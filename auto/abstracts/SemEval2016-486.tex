This paper presents our submissions for semantic textual similarity task in SemEval 2016. Based on various traditional features (i.e.,  string-based, corpus-based, machine translation similarity and alignment metrics, we leverage word embedding from macro (i.e., first get representation of sentence, then measure the similarity of sentence pair) and micro views (i.e., measure the similarity of word pairs seperately) to boost performance. Due to the various domains of training data and test data, we adopt three different strategies of the usage of training data: 1) U-SEVEN: an unsupervised model, which utilizes seven straight-forward metrics; 2) S1-All: use all available datasets; 3) S2: select the most similar training sets for each test set. Results on test sets show that a unified supervised model(i.e., S1-All) achieves the best averaged performance with a mean correlation of 75.07\%.
