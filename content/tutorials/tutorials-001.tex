\begin{tutorial}
  {English Resource Semantics}
  {Tutorials-001}
  {\daydateyear, \tutorialmorningtime}
  {\TutLocA}

Recent years have seen a dramatic increase in interest in semantically-informed natural language processing, including parsing into semantic representations, grounded language processing that connects linguistic structures to world representations, proposals to integrate compositional and distributional approaches to semantics, and approaches to semantically-sensitive tasks including sentiment analysis, summarization, generation, machine translation, and information extraction which take into account linguistic structure beyond n-grams. The semantic inputs to this work include a wide range of representations, from word embeddings, to syntactic dependencies used as a proxy for semantic dependencies, to sentence-level semantic representations either partial (e.g. semantic role labels) or fully articulated.

The purpose of this tutorial is to make accessible an important resource in this space, namely the semantic representations produced by the English Resource Grammar (ERG; Flickinger 2000, 2011). The ERG is a broad-coverage, linguistically motivated precision grammar for English, associating richly detailed semantic representations with input sentences. These representations, dubbed English Resource Semantics or ERS, are in the formalism of Minimal Recursion Semantics (MRS; Copestake et al 2005). They include not only semantic roles, but also information about the scope of quantifiers and scopal operators including negation, as well as semantic representations of linguistically complex phenomena such as time and date expressions, conditionals, and comparatives (Flickinger et al, 2014). ERS can be expressed in various ways, including a logic-based syntax using predicates and arguments, dependency graphs and dependency triples. In addition, the representations can be obtained either from existing manually produced annotations over texts from a variety of genres (the Redwoods Treebank, Oepen et al 2004) and DeepBank (Wall Street Journal corpus: Flickinger et al 2012) or by processing new text with the ERG and its associated parsing and parse selection algorithms.

With high parsing accuracy with rich semantic representations, English Resource Semantics is a valuable source of information for many semantically-sensitive NLP tasks. ERS-based systems have achieved state-of-the-art results in various tasks, including the identification of speculative or negated event mentions in biomedical text (MacKinlay et al 2011), question generation (Yao et al 2012), detecting the scope of negation (Packard et al 2014), relating natural language to robot control language (Packard 2014), and recognizing textual entailment (PETE task; Lien \& Kouylekov 2015). ERS representations have also been beneficial in semantic transfer-based MT (Oepen et al 2007, Bond et al 2011), ontology acquisition (Herbelot 2006), extraction of glossary sentences (Reiplinger et al 2012), sentiment analysis (Kramer \& Gordon 2014), and the ACL Anthology Searchbench (Sch√§fer et al 2011).

The goal of this tutorial is to make this resource more accessible to the ACL community. Specifically, we take as our learning goals that tutorial participants will learn how to: (1) set up the ERG-based parsing stack, including preprocessing; (2) access ERG Redwoods/DeepBank treebanks in the various export formats; and (3) interpret ERS representations.

\end{tutorial}

\begin{bio}
  {\bfseries Dan Flickinger} is a Senior Research Associate at CSLI at Stanford, and manager of the Linguistic Grammars Online (LinGO) Laboratory, where he is the principal developer of the LinGO English Resource Grammar (ERG), a precise broad-coverage implementation of HPSG. His primary research interests are in wide-coverage grammar engineering for both parsing and generation, lexical representation, the syntax-semantics interface, methodology for evaluation of semantically precise grammars, and practical applications of 'deep' processing. Applied and industrial experience includes co-founding the software company YY Technologies, which from 2000-2002 sold automated consumer email response technology incorporating the ERG; and since 2009 developing online educational software using the ERG for teaching English writing skills, first as part of the Education Program for Gifted Youth (EPGY) at Stanford, and for the past three years as a senior researcher at the EPGY spin-off company Redbird Advanced Learning, based in Oakland, California.

  {\bfseries Emily M. Bender} is a Professor in the Department of Linguistics and Associate Professor in the Department of Computer Science \& Engineering at the University of Washington. Her primary research interests lie in multilingual grammar engineering, semantic representations, and the incorporation of linguistic knowledge, especially from semantics and linguistic typology, in computational linguistics. She is the primary developer of the Grammar Matrix grammar customization system, which is developed in the context of the DELPH-IN Consortium (Deep Linguistic Processing with HPSG Initiative). Her book, \emph{Linguistic Fundamentals for Natural Language Processing: 100 Essentials from Morphology and Syntax} grew out of a NAACL 2012 tutorial on that topic.

  {\bfseries Woodley Packard} is a student at the University of Washington, pursuing a PhD in Computational Linguistics with Emily M. Bender. His research interests include efficient algorithms for grammar-based parsing, generation, annotation, and learning; robustness mechanisms for precision grammars; methodologies for contextually-informed disambiguation; and applications of semantic representations. He wrote and maintains the ACE parser/generator and the FFTB annotation tool. Recent work includes designing and building the top-performing entry for SemEval 2014 Task 6 on interpreting natural language commands to robots.

\end{bio}


