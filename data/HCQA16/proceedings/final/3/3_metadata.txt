SubmissionNumber#=%=#3
FinalPaperTitle#=%=#Attention-Based Convolutional Neural Network for Machine Comprehension
ShortPaperTitle#=%=#Attention-Based Convolutional Neural Network for Machine Comprehension
NumberOfPages#=%=#7
CopyrightSigned#=%=#Wenpeng Yin
JobTitle#==#
Organization#==#LMU Munich,   Oettingenstr.67, 80538 Munich, Germany
Abstract#==#Understanding open-domain text is one of the primary
challenges in NLP. Machine
comprehension benchmarks evaluate a system's ability to understand
text based on
the text content only. In this work, we investigate machine
comprehension on MCTest, a question answering (QA) benchmark. Prior work
is mainly based on feature engineering approaches. We come
up with a neural network framework, named hierarchical
attention-based convolutional neural network (HABCNN), to
address this task without any manually designed
features. Specifically, we explore HABCNN for this task by
two routes, one is through traditional joint modeling
of document, question and answer, one is through textual
entailment. HABCNN employs an attention mechanism to detect key
phrases, key sentences and key snippets that are relevant to
answering the question. Experiments show that
HABCNN outperforms prior deep learning approaches
by a big margin.
Author{1}{Firstname}#=%=#Wenpeng
Author{1}{Lastname}#=%=#Yin
Author{1}{Email}#=%=#mr.yinwenpeng@gmail.com
Author{1}{Affiliation}#=%=#University of Munich
Author{2}{Firstname}#=%=#Sebastian
Author{2}{Lastname}#=%=#Ebert
Author{2}{Email}#=%=#ebert@cis.lmu.de
Author{2}{Affiliation}#=%=#Center for Information and Language Processing, University of Munich
Author{3}{Firstname}#=%=#Hinrich
Author{3}{Lastname}#=%=#Sch√ºtze
Author{3}{Email}#=%=#inquiries@cislmu.org
Author{3}{Affiliation}#=%=#Center for Information and Language Processing, University of Munich

==========