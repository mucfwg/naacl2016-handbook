SubmissionNumber#=%=#22
FinalPaperTitle#=%=#Row-less Universal Schema
ShortPaperTitle#=%=#Row-less Universal Schema
NumberOfPages#=%=#6
CopyrightSigned#=%=#Patrick Verga
JobTitle#==#
Organization#==#University of Massachusetts Amherst
College of Information and Computer Sciences
40 Governors Dr., Amherst, MA 01003
Abstract#==#Universal schema jointly embeds knowledge bases and textual patterns to reason
about entities and relations for automatic knowledge base construction and
information extraction.
In the past, entity pairs and relations were represented as learned vectors
with compatibility determined by a scoring function, limiting generalization to
unseen text patterns and entities.
Recently, `column-less' versions of Universal Schema have used compositional
pattern encoders to generalize to all text patterns.
In this work we take the next step and propose a `row-less' model of universal
schema, removing explicit entity pair representations.
Instead of learning vector representations for each entity pair in our training
set, we treat an entity pair as a function of its relation types.
In experimental results on the FB15k-237 benchmark we demonstrate that we can
match the performance of a comparable model with explicit entity pair
representations using a model of attention over relation types.
We further demonstrate that the model performs with nearly the same accuracy on
entity pairs never seen during training.
Author{1}{Firstname}#=%=#Patrick
Author{1}{Lastname}#=%=#Verga
Author{1}{Email}#=%=#pat@cs.umass.edu
Author{1}{Affiliation}#=%=#UMass Amherst
Author{2}{Firstname}#=%=#Andrew
Author{2}{Lastname}#=%=#McCallum
Author{2}{Email}#=%=#mccallum@cs.umass.edu
Author{2}{Affiliation}#=%=#UMass Amherst

==========