SubmissionNumber#=%=#39
FinalPaperTitle#=%=#``Why Should I Trust You?'': Explaining the Predictions of Any Classifier
ShortPaperTitle#=%=#``Why Should I Trust You?'': Explaining the Predictions of Any Classifier
NumberOfPages#=%=#5
CopyrightSigned#=%=#Sameer Singh
JobTitle#==#Research Associate
Organization#==#University of Washington
185 Stevens Way
Seattle WA 98195
Abstract#==#Despite widespread adoption in NLP, machine learning models remain mostly black
boxes. Understanding the reasons behind predictions is, however, quite
important in assessing trust in a model. Trust is fundamental if one plans to
take action based on a prediction, or when choosing whether or not to deploy a
new model.
In this work, we describe LIME, a novel explanation technique that explains the
predictions of any classifier in an interpretable and faithful manner. We
further present a method to explain models by presenting representative
individual predictions and their explanations in a non-redundant manner. We
propose a demonstration of these ideas on different NLP tasks such as document
classification, politeness detection, and twitter sentiment analysis, with
classifiers like neural networks and SVMs. The user interactions include
explanations of free-form text, challenging users to identify the better
classifier from a pair, and perform basic feature engineering to improve the
classifiers.
Author{1}{Firstname}#=%=#Marco
Author{1}{Lastname}#=%=#Ribeiro
Author{1}{Email}#=%=#marcotcr@cs.washington.edu
Author{1}{Affiliation}#=%=#University of Washington
Author{2}{Firstname}#=%=#Sameer
Author{2}{Lastname}#=%=#Singh
Author{2}{Email}#=%=#sameer@cs.washington.edu
Author{2}{Affiliation}#=%=#University of Washington, Seattle
Author{3}{Firstname}#=%=#Carlos
Author{3}{Lastname}#=%=#Guestrin
Author{3}{Email}#=%=#guestrin@cs.washington.edu
Author{3}{Affiliation}#=%=#University of Washington

==========