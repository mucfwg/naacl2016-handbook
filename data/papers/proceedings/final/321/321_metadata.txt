SubmissionNumber#=%=#321
FinalPaperTitle#=%=#Unsupervised Compound Splitting With Distributional Semantics Rivals Supervised Methods
ShortPaperTitle#=%=#Unsupervised Compound Splitting With Distributional Semantics Rivals Supervised Methods
NumberOfPages#=%=#6
CopyrightSigned#=%=#Martin
JobTitle#==#
Organization#==#Language Technology
TU Darmstadt
Hochschulstra√üe 10
64289 Darmstadt
Abstract#==#In this paper we present a word decompounding method that is based on
distributional semantics. Our method does not require on any linguistic
knowledge and is initialized using a large monolingual corpus. The core idea of
our approach is that parts of single-word compounds (like "candle" and "stick")
are semantically similar to the entire compound, which helps to exclude
spurious splits (like "candles" "tick"). 
We report results for German and Dutch: For German, our unsupervised method
comes on par with the performance of a rule-based and a supervised method and
outperforms two unsupervised baselines. For Dutch, our method performs only
slightly below a rule-based optimized compound splitter.
Author{1}{Firstname}#=%=#Martin
Author{1}{Lastname}#=%=#Riedl
Author{1}{Email}#=%=#riedl@cs.tu-darmstadt.de
Author{1}{Affiliation}#=%=#TU Darmstadt
Author{2}{Firstname}#=%=#Chris
Author{2}{Lastname}#=%=#Biemann
Author{2}{Email}#=%=#biem@cs.tu-darmstadt.de
Author{2}{Affiliation}#=%=#TU Darmstadt

==========