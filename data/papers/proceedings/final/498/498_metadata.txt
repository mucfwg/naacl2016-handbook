SubmissionNumber#=%=#498
FinalPaperTitle#=%=#Vision and Feature Norms: Improving automatic feature norm learning through cross-modal maps
ShortPaperTitle#=%=#Vision and Feature Norms: Improving automatic feature norm learning through cross-modal maps
NumberOfPages#=%=#10
CopyrightSigned#=%=#Luana Bulat
JobTitle#==#
Organization#==#
Abstract#==#Property norms have the potential to aid a wide range of semantic tasks,
provided that they can be obtained for large numbers of concepts. Recent work
has focused on text as the main source of information for automatic property
extraction. In this paper we examine property norm prediction from visual,
rather than textual, data, using cross-modal maps learnt between property norm
and visual spaces. We also investigate the importance of having a complete
feature norm dataset, for both training and testing. Finally, we evaluate how
these datasets and cross-modal maps can be used in an image retrieval task.
Author{1}{Firstname}#=%=#Luana
Author{1}{Lastname}#=%=#Bulat
Author{1}{Email}#=%=#ltf24@cam.ac.uk
Author{1}{Affiliation}#=%=#University of Cambridge
Author{2}{Firstname}#=%=#Douwe
Author{2}{Lastname}#=%=#Kiela
Author{2}{Email}#=%=#douwe.kiela@cl.cam.ac.uk
Author{2}{Affiliation}#=%=#University of Cambridge Computer Laboratory
Author{3}{Firstname}#=%=#Stephen
Author{3}{Lastname}#=%=#Clark
Author{3}{Email}#=%=#sc609@cam.ac.uk
Author{3}{Affiliation}#=%=#University of Cambridge

==========