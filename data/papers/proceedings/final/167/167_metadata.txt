SubmissionNumber#=%=#167
FinalPaperTitle#=%=#The Role of Context Types and Dimensionality in Learning Word Embeddings
ShortPaperTitle#=%=#The Role of Context Types and Dimensionality in Learning Word Embeddings
NumberOfPages#=%=#11
CopyrightSigned#=%=#Oren Melamud
JobTitle#==#student
Organization#==#Bar Ilan University
Abstract#==#We provide the first extensive evaluation of how using different types of
context to learn skip-gram word embeddings affects performance on a wide range
of intrinsic and extrinsic NLP tasks. Our results suggest that while intrinsic
tasks tend to exhibit a clear preference to particular types of contexts and
higher dimensionality, more careful tuning is required for finding the optimal
settings for most of the extrinsic tasks that we considered.
Furthermore, for these extrinsic tasks, we find that once the benefit from
increasing the embedding dimensionality is mostly exhausted, simple
concatenation of word embeddings, learned with different context types, can
yield further performance gains. As an additional contribution, we propose a
new variant of the skip-gram model that learns word embeddings from weighted
contexts of substitute words.
Author{1}{Firstname}#=%=#Oren
Author{1}{Lastname}#=%=#Melamud
Author{1}{Email}#=%=#melamuo@cs.biu.ac.il
Author{1}{Affiliation}#=%=#Bar Ilan University
Author{2}{Firstname}#=%=#David
Author{2}{Lastname}#=%=#McClosky
Author{2}{Email}#=%=#dmcc@cs.stanford.edu
Author{2}{Affiliation}#=%=#Google
Author{3}{Firstname}#=%=#Siddharth
Author{3}{Lastname}#=%=#Patwardhan
Author{3}{Email}#=%=#siddharth@us.ibm.com
Author{3}{Affiliation}#=%=#IBM T. J. Watson Research Center
Author{4}{Firstname}#=%=#Mohit
Author{4}{Lastname}#=%=#Bansal
Author{4}{Email}#=%=#mbansal@ttic.edu
Author{4}{Affiliation}#=%=#Toyota Technological Institute at Chicago

==========