SubmissionNumber#=%=#164
FinalPaperTitle#=%=#Top-down Tree Long Short-Term Memory Networks
ShortPaperTitle#=%=#Top-down Tree Long Short-Term Memory Networks
NumberOfPages#=%=#11
CopyrightSigned#=%=#Xingxing Zhang
JobTitle#==#
Organization#==#School of Informatics, University of Edinburgh,
10 Crichton Street, Edinburgh EH8 9AB, UK
Abstract#==#Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with
a more complex computational unit, have been successfully applied to a variety
of sequence modeling tasks. In this paper we develop Tree Long Short-Term
Memory (TreeLSTM), a neural network model based on LSTM, which is designed to
predict a tree rather than a linear sequence. TreeLSTM defines the probability
of a sentence by estimating the generation probability of its
dependency tree. At each time step, a node is generated based on the
representation of the generated sub-tree. We further enhance the modeling
power of TreeLSTM by explicitly representing the correlations between left and
right dependents. Application of our model to the MSR sentence completion
challenge achieves results beyond the current state of the art. We also
report results on dependency parsing reranking achieving competitive
performance.
Author{1}{Firstname}#=%=#Xingxing
Author{1}{Lastname}#=%=#Zhang
Author{1}{Email}#=%=#zxxpku@gmail.com
Author{1}{Affiliation}#=%=#Institute for Language, Cognition and Computation, School of Informatics, University of Edinburgh
Author{2}{Firstname}#=%=#Liang
Author{2}{Lastname}#=%=#Lu
Author{2}{Email}#=%=#liang.lu@ed.ac.uk
Author{2}{Affiliation}#=%=#School of Informatics, University of Edinburgh
Author{3}{Firstname}#=%=#Mirella
Author{3}{Lastname}#=%=#Lapata
Author{3}{Email}#=%=#mlap@inf.ed.ac.uk
Author{3}{Affiliation}#=%=#School of Informatics, University of Edinburgh

==========