SubmissionNumber#=%=#162
FinalPaperTitle#=%=#Probabilistic Models for Learning a Semantic Parser Lexicon
ShortPaperTitle#=%=#Probabilistic Models for Learning a Semantic Parser Lexicon
NumberOfPages#=%=#11
CopyrightSigned#=%=#Jayant Krishnamurthy
JobTitle#==#
Organization#==#Allen Institute for Artificial Intelligence
2157 N. Northlake Way, Suite 110
Seattle, WA 98103
Abstract#==#We introduce several probabilistic models for learning the lexicon of a
semantic parser. Lexicon learning is the first step of training a semantic
parser for a new application domain and the quality of the learned lexicon
significantly impacts both the accuracy and efficiency of the final semantic
parser. Existing work on lexicon learning has focused on heuristic methods that
lack convergence guarantees and require significant human input in the form of
lexicon templates or annotated logical forms. In contrast, our probabilistic
models are trained directly from question/answer pairs using EM and our
simplest model has a concave objective that guarantees convergence to a global
optimum. An experimental evaluation on a set of 4th grade science questions
demonstrates that our models improve semantic parser accuracy (35-70% error
reduction) and efficiency (4-25x more sentences per second) relative to prior
work despite using less human input. Our models also obtain competitive results
on Geo880 without any dataset-specific engineering.
Author{1}{Firstname}#=%=#Jayant
Author{1}{Lastname}#=%=#Krishnamurthy
Author{1}{Email}#=%=#jayantk@allenai.org
Author{1}{Affiliation}#=%=#Allen Institute for Artificial Intelligence

==========