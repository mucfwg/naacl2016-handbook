SubmissionNumber#=%=#227
FinalPaperTitle#=%=#Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism
ShortPaperTitle#=%=#Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism
NumberOfPages#=%=#10
CopyrightSigned#=%=#Orhan Firat
JobTitle#==#
Organization#==#Middle East Technical University
Abstract#==#We propose multi-way, multilingual neural machine translation. The proposed
approach enables a single neural translation model to translate between
multiple languages, with a number of parameters that grows only linearly with
the number of languages. This is made possible by having a single attention
mechanism that is shared across all language pairs. We train the proposed
multi-way, multilingual model on ten language pairs from WMTâ€™15
simultaneously and observe clear performance improvements over models trained
on only one language pair. In particular, we observe that the proposed model
significantly improves the translation quality of low-resource language pairs.
Author{1}{Firstname}#=%=#Orhan
Author{1}{Lastname}#=%=#Firat
Author{1}{Email}#=%=#e1697481@ceng.metu.edu.tr
Author{1}{Affiliation}#=%=#Middle East Technical University
Author{2}{Firstname}#=%=#Kyunghyun
Author{2}{Lastname}#=%=#Cho
Author{2}{Email}#=%=#kyunghyun.cho@nyu.edu
Author{2}{Affiliation}#=%=#New York University
Author{3}{Firstname}#=%=#Yoshua
Author{3}{Lastname}#=%=#Bengio
Author{3}{Email}#=%=#yoshua.bengio@umontreal.ca
Author{3}{Affiliation}#=%=#University of Montreal

==========