SubmissionNumber#=%=#559
FinalPaperTitle#=%=#LSTM CCG Parsing
ShortPaperTitle#=%=#LSTM CCG Parsing
NumberOfPages#=%=#11
CopyrightSigned#=%=#Mike Lewis
JobTitle#==#
Organization#==#Computer Science & Engineering
University of Washington
AC101 Paul G. Allen Center for
     Computer Science & Engineering
Box 352350
185 Stevens Way
Seattle WA 98195-2350
Abstract#==#We demonstrate that a state-of-the-art parser can be built using only a lexical
tagging model and a deterministic grammar, with no explicit model of bi-lexical
dependencies.  Instead, all dependencies are implicitly encoded in an LSTM
supertagger that assigns CCG lexical categories. The parser significantly
outperforms all previously published CCG results, supports efficient and
optimal A* decoding, and benefits substantially from  semi-supervised
tri-training. We give a detailed analysis, demonstrating that the parser can
recover long-range dependencies with high accuracy and that the semi-supervised
learning enables significant accuracy gains.
By running the LSTM on a GPU, we are able to parse over 2600 sentences per
second while improving state-of-the-art accuracy by 1.1 F1 in domain and up to
4.5 F1 out of domain.
Author{1}{Firstname}#=%=#Mike
Author{1}{Lastname}#=%=#Lewis
Author{1}{Email}#=%=#mikelewis0@gmail.com
Author{1}{Affiliation}#=%=#University of Washington
Author{2}{Firstname}#=%=#Kenton
Author{2}{Lastname}#=%=#Lee
Author{2}{Email}#=%=#kentonl@cs.washington.edu
Author{2}{Affiliation}#=%=#University of Washington
Author{3}{Firstname}#=%=#Luke
Author{3}{Lastname}#=%=#Zettlemoyer
Author{3}{Email}#=%=#lsz@cs.washington.edu
Author{3}{Affiliation}#=%=#University of Washington

==========