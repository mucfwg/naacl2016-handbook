SubmissionNumber#=%=#52
FinalPaperTitle#=%=#Sentence-Level Grammatical Error Identification as Sequence-to-Sequence Correction
ShortPaperTitle#=%=#Sentence-Level Grammatical Error Identification as Sequence-to-Sequence Correction
NumberOfPages#=%=#10
CopyrightSigned#=%=#Allen Schmaltz
JobTitle#==#
Organization#==#Harvard University, Cambridge, MA
Abstract#==#We demonstrate that an attention-based encoder-decoder model can be used for
sentence-level grammatical error identification for the Automated Evaluation of
Scientific Writing (AESW) Shared Task 2016. The attention-based encoder-decoder
models can be used for the generation of corrections, in addition to error
identification, which is of interest for certain end-user applications. We show
that a character-based encoder-decoder model is particularly effective,
outperforming other results on the AESW Shared Task on its own, and showing
gains over a word-based counterpart. Our final model--a combination of three
character-based encoder-decoder models, one word-based encoder-decoder model,
and a sentence-level CNN--is the highest performing system on the AESW 2016
binary prediction Shared Task.
Author{1}{Firstname}#=%=#Allen
Author{1}{Lastname}#=%=#Schmaltz
Author{1}{Email}#=%=#schmaltz@fas.harvard.edu
Author{1}{Affiliation}#=%=#Harvard University
Author{2}{Firstname}#=%=#Yoon
Author{2}{Lastname}#=%=#Kim
Author{2}{Email}#=%=#yoonkim@seas.harvard.edu
Author{2}{Affiliation}#=%=#Harvard University
Author{3}{Firstname}#=%=#Alexander M.
Author{3}{Lastname}#=%=#Rush
Author{3}{Email}#=%=#srush@seas.harvard.edu
Author{3}{Affiliation}#=%=#Harvard University
Author{4}{Firstname}#=%=#Stuart
Author{4}{Lastname}#=%=#Shieber
Author{4}{Email}#=%=#shieber@seas.harvard.edu
Author{4}{Affiliation}#=%=#

==========